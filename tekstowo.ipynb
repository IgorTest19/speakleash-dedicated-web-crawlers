{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#url = 'https://www.tekstowo.pl/artysci_na,A,strona,1.html'\n",
    "# R:  pages = [i for i in range(1, 11)]\n",
    "pages = list(range(1,11)) # R: we can shorten the above creation of list of ints\n",
    "domain = 'https://tekstowo.pl'\n",
    "urls = []\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "# Extracting the artist list\n",
    "# it is good to use more intuitive names, also the 'i' variable is also used in the loop below\n",
    "for page in pages:\n",
    "    url = f'https://www.tekstowo.pl/artysci_na,A,strona,{page}.html'\n",
    "    try:\n",
    "        req = requests.get(url)\n",
    "        if req.ok:\n",
    "            soup = BeautifulSoup(req.content, 'lxml')\n",
    "            # R: we can use range instead of enumreate if we are not using 'i' variable\n",
    "            for i, link in enumerate(soup.find_all('a')):\n",
    "                # R: if type(link.get('href')) == str and 'piosenki_' in link.get('href'):\n",
    "                if isinstance(link.get('href'), str) and 'piosenki_' in link.get('href'):# it is safer to use isinstance\n",
    "                    urls.append(link.get('href'))\n",
    "\n",
    "            #print(soup.prettify())\n",
    "            #art = soup.find_all(class_='title')\n",
    "\n",
    "            #print(art)\n",
    "\n",
    "    except Exception as e:\n",
    "        cnt += 1\n",
    "        print(e)\n",
    "\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_number(url: str) -> int: # R: added typehints\n",
    "\t\"\"\"\n",
    "\tGet the highest page number per given letter.\n",
    "\t\"\"\"\n",
    "\tmax_page = 0\n",
    "\n",
    "\treq = requests.get(url)\n",
    "\tif req.ok:\n",
    "\t\tsoup = BeautifulSoup(req.content, 'lxml')\n",
    "\t\tfor page in soup.find_all(class_='page-link'):\n",
    "\t\t\t# R: we can make these 2 conditions into one liner\n",
    "\t\t\t# R: if page.text.isnumeric():\n",
    "\t\t\t# \tR: if int(page.text) > max_page:\n",
    "\t\t\tif page.text.isnumeric() and int(page.text) > max_page:\n",
    "\t\t\t\tmax_page = int(page.text)\n",
    "# \t\t\tif page.text.isnumeric():\n",
    "# \t\t\t\tif int(page.text) > max_page:\n",
    "# \t\t\t\t\tmax_page = int(page.text)\n",
    "\t#print(f\"Max page: {max_page}\")\n",
    "\treturn max_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "def create_lut_pagination():\n",
    "    \"\"\"\n",
    "    Creates a look-up table for each letter containing max page number\n",
    "    \"\"\"\n",
    "\n",
    "    # R: remove below imports above the function\n",
    "    # import string\n",
    "    # import time\n",
    "    \n",
    "    # R: we can use oneline in this case (it is not as readable as the original solution)\n",
    "    # R: alphabet = string.ascii_letters.upper()\n",
    "    # R: alphabet = sorted(list(set(alphabet)))\n",
    "    # R: alphabet.append('pozostale')\n",
    "    # R: we can use oneline in this case (it is not as readable as solution above)\n",
    "    \n",
    "    # R: alphabet = sorted(set(string.ascii_letter.upper()))\n",
    "    alphabet = list(string.ascii_uppercase) + ['pozostałe']\n",
    "    \n",
    "    lut_pages = {}\n",
    "\n",
    "    for letter in alphabet:\n",
    "        time.sleep(5)\n",
    "        url = f\"https://www.tekstowo.pl/artysci_na,{letter}.html\"\n",
    "        lut_pages[letter] = get_pages_number(url)\n",
    "        print(f\"Letter {letter} has {lut_pages[letter]} pages of artists.\")\n",
    "    print(type(lut_pages))\n",
    "    return lut_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter A has 538 pages of artists.\n",
      "Letter B has 385 pages of artists.\n",
      "Letter C has 363 pages of artists.\n",
      "Letter D has 411 pages of artists.\n",
      "Letter E has 226 pages of artists.\n",
      "Letter F has 189 pages of artists.\n",
      "Letter G has 210 pages of artists.\n",
      "Letter H has 219 pages of artists.\n",
      "Letter I has 130 pages of artists.\n",
      "Letter J has 337 pages of artists.\n",
      "Letter K has 315 pages of artists.\n",
      "Letter L has 311 pages of artists.\n",
      "Letter M has 534 pages of artists.\n",
      "Letter N has 204 pages of artists.\n",
      "Letter O has 116 pages of artists.\n",
      "Letter P has 287 pages of artists.\n",
      "Letter Q has 15 pages of artists.\n",
      "Letter R has 272 pages of artists.\n",
      "Letter S has 574 pages of artists.\n",
      "Letter T has 482 pages of artists.\n",
      "Letter U has 46 pages of artists.\n",
      "Letter V has 118 pages of artists.\n",
      "Letter W has 141 pages of artists.\n",
      "Letter X has 18 pages of artists.\n",
      "Letter Y has 77 pages of artists.\n",
      "Letter Z has 68 pages of artists.\n",
      "Letter pozostałe has 538 pages of artists.\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "max_page_per_letter = create_lut_pagination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artists(letter):\n",
    "\t\"\"\"\n",
    "\tScrape all of the artists starting with a given letter in the alphabet.\n",
    "\t\"\"\"\n",
    "\timport time\n",
    "\turls = []\n",
    "\tlimit = max_page_per_letter[letter]+1\n",
    "\n",
    "\tfor page in range(1, limit):\n",
    "\n",
    "\t\turl = f\"https://www.tekstowo.pl/artysci_na,{letter},strona,{page}.html\"\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\ttime.sleep(1)\n",
    "\t\t\tresponse = requests.get(url)\n",
    "\t\t\tif response.ok:\n",
    "\t\t\t\tsoup = BeautifulSoup(response.content, 'lxml')\n",
    "\t\t\t\tfor link in soup.find_all('a'):\n",
    "\t\t\t\t\titem = link.get('href')\n",
    "\t\t\t\t\tif type(item) == str and 'piosenki_' in item:\n",
    "\t\t\t\t\t\turls.append('https://tekstowo.pl' + item)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(e)\n",
    "\t\tprint(f\"Visited {page}/{limit}\")\n",
    "\tprint(f\"Collected {len(urls)} artists\")\n",
    "\treturn urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_artists(\"Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_url = \"https://www.tekstowo.pl/piosenki_artysty,q_tip.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_songs(artist_url):\n",
    "\timport requests\n",
    "\timport time\n",
    "\n",
    "\turls = []\n",
    "\n",
    "\tnext_page_available = True\n",
    "\n",
    "\n",
    "\t# Link construction differs, approach to be revised\n",
    "\t#limit = get_pages_number(artist_url)\n",
    "\t#print(limit)\n",
    "\n",
    "\twhile next_page_available:\n",
    "\t\ttime.sleep(5)\t\t\n",
    "\t\ttry:\n",
    "\t\t\tresponse = requests.get(artist_url)\n",
    "\t\t\tif response.ok:\n",
    "\t\t\t\t# Create BS instance\n",
    "\t\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\t\t\t\t# Extract all songs from the webpage\n",
    "\t\t\t\tsongs = soup.find_all(class_='box-przeboje')\n",
    "\n",
    "\t\t\t\t# Extract the artist\n",
    "\t\t\t\tartist = soup.find(class_=\"col-md-7 col-lg-8 px-0\")\n",
    "\t\t\t\tartist = artist.text.split(\" (\")[0].strip()\n",
    "\t\t\t\t#print(f'Artist: {artist}')\n",
    "\n",
    "\t\t\t\t# Iterate through every song and collect URL\n",
    "\t\t\t\tfor song in songs:\n",
    "\t\t\t\t\tsong_title_element = song.find(class_='title')\n",
    "\n",
    "\t\t\t\t\tif song_title_element:\n",
    "\t\t\t\t\t\tif artist in song_title_element.text.strip():\n",
    "\t\t\t\t\t\t\t#song_title = song_title_element.text.strip()\n",
    "\t\t\t\t\t\t\tsong_url = \"https://tekstowo.pl\" + song_title_element['href']\n",
    "\t\t\t\t\t\t\t#print(song_title, song_url)\n",
    "\t\t\t\t\t\t\tif not \".plpiosenka\" in song_url and song_url not in urls: # dealing with invalid URLs and duplicates\n",
    "\t\t\t\t\t\t\t\turls.append(song_url)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Check if the 'next page' button exists\n",
    "\t\t\t\tbutton_next_page = soup.find_all(class_='page-link')[-1]\n",
    "\t\t\t\tif 'następna' in button_next_page.text.lower():\n",
    "\t\t\t\t\tartist_url = \"https://tekstowo.pl\" + button_next_page['href']\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnext_page_available = False\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(e)\n",
    "\t\t\t\n",
    "\tprint(f\"Collected {len(urls)} song URLs\")\n",
    "\treturn urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 38 song URLs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://tekstowo.pl/piosenka,q_tip,life_is_better___feat__norah_jones__.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,breath_and_stop.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,we_fight___we_love.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,gettin_up.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,do_it.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,end_of_time.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,all_in.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,amplified.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,believe.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,buddy.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,dance_on_glass.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,do_it__see_it__be_it.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,don_8217_t_go_breaking_my_heart__feat__demi_lovato_.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,for_the_nasty.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,get_involved.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,go_hard.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,good_thang.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,hey.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,higher.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,johnny_is_dead.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,just_a_lil_dude__who_dat_ovah_there_.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,let_s_ride.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,manwomanboogie.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,move.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,moving_with_u.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,n_t.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,official.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,renaissance_rap.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,shaka.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,the_fear_in_the_heart_of_a_man.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,things_you_do.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,vivrant_thang__special_girl_remix_.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,vivrant_thing.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,vivrant_thing_remix.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,wait_up.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,what_lies_beneath.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,won_t_trade.html',\n",
       " 'https://tekstowo.pl/piosenka,q_tip,you.html']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_artist_songs(artist_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_url = \"https://www.tekstowo.pl/piosenka,f__kiepski__h__kiepska__m__kiepska,jestem_motylem__odcinek_337_.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_song(song_url):\n",
    "\tsong = \"\"\n",
    "\tsong_translation = None\n",
    "\n",
    "\ttry:\n",
    "\t\tresponse = requests.get(song_url)\n",
    "\t\tif response.ok:\n",
    "\t\t\tsoup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "\t\t\t# Original song\n",
    "\t\t\tsong_html = soup.find(class_='inner-text')\t\t\t\n",
    "\t\t\tsong = song_html.text.strip()\n",
    "\n",
    "\t\t\t# Translated version\n",
    "\t\t\ttransl_html = soup.find('div', id='translation')\n",
    "\t\t\tsong_translation = transl_html.text.strip()\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\n",
    "\treturn song, song_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1, text2 = extract_song(song_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_language(song_text):\n",
    "\timport langdetect\n",
    "\n",
    "\tif not isinstance(song_text, str):\n",
    "\t\treturn False\n",
    "\t\n",
    "\telif len(song_text) == 0:\n",
    "\t\traise TypeError(\"Empty file\")\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\treturn langdetect.detect(song_text)\n",
    "\t\texcept langdetect.lang_detect_exception.LangDetectException:\n",
    "\t\t\treturn \"Language detection failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Empty file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m assess_language(text2)\n",
      "Cell \u001b[0;32mIn[173], line 8\u001b[0m, in \u001b[0;36massess_language\u001b[0;34m(song_text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(song_text) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m \t\u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty file\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mEmpty file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Empty file"
     ]
    }
   ],
   "source": [
    "assess_language(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
